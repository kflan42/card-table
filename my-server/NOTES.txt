# To run from fresh checkout:
## close IDEs while running installs else files get stuck
cd my-server
python3 -m venv "venv"
source venv/bin/activate
pip3 install -r requirements.txt
./genTsInterfaces.sh
# then do local part of cards update and frontend build

# Cloud cards update
cd scryfall; python3 updateCards.py; extractCards.sh
gsutil cp -r ../my-server/cards gs://${GOOGLE_CLOUD_PROJECT}.appspot.com

# Cloud frontend update
cd my-app; npm install;
./rebuildForServer.sh $MY_API_SERVER_URL
gsutil cp -r build/*  gs://$FRONTEND_BUCKET
gsutil iam ch allUsers:legacyObjectReader gs://$FRONTEND_BUCKET
gsutil web set -m index.html -e index.html gs://$FRONTEND_BUCKET

# Cloud server update
cd my-server
gcloud app deploy --version VERSION --verbosity info
gcloud app deploy dispatch.yaml
gcloud app deploy cron.yaml
# repeat for table-admin-server, except it is currently unused

# Cloud Func update
cd cloud-func
gcloud functions deploy card_update --runtime python39 --trigger-http --region $REGION --update-env-vars MY_CLOUD_PROJECT=$GOOGLE_CLOUD_PROJECT
# give it 4GB of memory and 120s max runtime, it currently uses ~2GB and runs in ~60s.
# setup cloud scheduler job and service account to call it
# https://cloud.google.com/scheduler/docs/http-target-auth#using-the-console

# for local debug
export FLASK_DEV True; export BASE_IP localhost; export BASE_PORT 5000
python3 hello.py
# Optionally run a dev ui from
cd my-app; npm start

# Local run using cloud storage
export GOOGLE_APPLICATION_CREDENTIALS=$$$_key.json
export GOOGLE_CLOUD_PROJECT=
gunicorn --worker-class eventlet -w 1 hello:app

# Can run redis via:
windows powershell, bash -l, redis-server /home/linuxbrew/.linuxbrew/etc/redis.conf
monitor it via powershell, bash -l, redis-cli, monitor
